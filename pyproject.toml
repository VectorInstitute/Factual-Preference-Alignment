[project]
name = "AIXpert_preference_alignment"
version = "0.1.0"
description = "Replication Learning LLM-as-a-Judge for Preference Alignment"
readme = "README.md"
authors = [{ name = "Sindhuja Chaduvula", email = "sindhuja.chaduvula@vectorinstitute.ai" }]
license = "MIT"
requires-python = ">=3.10,<3.12"

dependencies = [
    "python-dotenv==1.1",
    "torch==2.6.0+cu124",
    "torchaudio==2.6.0+cu124",
    "torchvision==0.21.0+cu124",
    "cmake==4.1.0",
    "ninja>=1.13.0",
    "pyarrow==15.0.2",
    "unsloth[colab-new]",
    "einops>=0.8.1",
    "setuptools>=80.9.0",
    "wheel>=0.45.1",
    "build>=1.3.0",
    "trl==0.22.2",
    "peft>=0.17.1",
    "accelerate==1.10.1",
    "bitsandbytes==0.48.1",
    "unsloth-zoo>=2025.10.10",
    "wandb>=0.22.2",
    "flash-attn==2.7.3",
    "sentence-transformers>=5.1.2",
    "openai>=2.6.1",
    "pydantic-settings>=2.11.0",
    "jsonlines>=4.0.0",
    "seaborn>=0.13.2",
    "aiofiles>=25.1.0",
    "tiktoken==0.7.0",
    "opik>=1.9.33",
]

[tool.uv]
index-url = "https://pypi.org/simple"
extra-index-url = ["https://download.pytorch.org/whl/cu124"]
index-strategy = "unsafe-best-match"

[tool.uv.sources]
unsloth = { git = "https://github.com/unslothai/unsloth.git" }

